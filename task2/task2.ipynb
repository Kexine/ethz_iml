{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.impute import (SimpleImputer, KNNImputer, IterativeImputer)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "np.set_printoptions(precision = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df_train_features = pd.read_csv('train_features.csv', index_col=0)\n",
    "df_train_labels   = pd.read_csv('train_labels.csv', index_col=0)\n",
    "df_test_features  = pd.read_csv('test_features.csv', index_col=0)\n",
    "\n",
    "x_ = df_train_features.values[:,1:]\n",
    "y_ = df_train_labels.values\n",
    "x_test = df_test_features.values[:,1:]\n",
    "\n",
    "IdF_ = df_train_features.index\n",
    "IdL_ = df_train_labels.index\n",
    "IdF_test_ = df_test_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract population statistics (mean, std, ...) for each column for imputation \n",
    "# ignoring Nan values\n",
    "pop_mean = np.nanmean(x_, axis = 0)\n",
    "pop_median = np.nanmedian(x_, axis = 0)\n",
    "pop_std = np.nanstd(x_, axis = 0)\n",
    "\n",
    "pop_mean_test = np.nanmean(x_test, axis = 0)\n",
    "pop_median_test = np.nanmedian(x_test, axis = 0)\n",
    "pop_std_test = np.nanstd(x_test, axis = 0)\n",
    "\n",
    "# Extract unique PIDs creating a dictionary\n",
    "IdF_unique = pd.unique(IdF_) # feature indexes\n",
    "IdL_unique = pd.unique(IdL_) # label indexes\n",
    "IdF_test_unique = pd.unique(IdF_test_) # feature indexes\n",
    "\n",
    "print(~np.any(IdF_unique - IdL_unique)) # should be True, meaning that IdF_unique and IdL_unique are exactly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing Strategy (depends on how many nan values in each column)\n",
    "def impute_strategy(nb_Nan):\n",
    "    if nb_Nan >= 12:\n",
    "        strategy = 'C'\n",
    "    elif (nb_Nan>=5) and (nb_Nan<12):\n",
    "        strategy = 'M'\n",
    "    elif (nb_Nan < 5) and (nb_Nan>0):\n",
    "        strategy = 'I'\n",
    "    return strategy\n",
    "\n",
    "# Impute Data function\n",
    "def impute_data(strategy, col_median):\n",
    "    \n",
    "    if strategy == 'C':\n",
    "    # Estimate the score after replacing missing values by 0\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=col_median)\n",
    "    \n",
    "    if strategy == 'M':\n",
    "    # Estimate the score after imputation (mean strategy) of the missing values\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='median', fill_value=None)\n",
    "    \n",
    "    if strategy == 'KNN':\n",
    "    # Estimate the score after kNN-imputation of the missing values\n",
    "        imputer = KNNImputer(missing_values=np.nan, n_neighbors=5, weights='distance', metric='nan_euclidean')\n",
    "    \n",
    "    if strategy == 'I':\n",
    "    # Estimate the score after iterative imputation of the missing values\n",
    "        imputer = IterativeImputer(estimator=BayesianRidge(), missing_values=np.nan, max_iter=10, tol=0.001, n_nearest_features=5, initial_strategy='mean')\n",
    "    \n",
    "    return imputer\n",
    "\n",
    "# Function to get patient'x data from it's ID number\n",
    "def get_patient_data(pid_index):\n",
    "    return x_[pid_index*12:pid_index*12 + 12, :]\n",
    "\n",
    "def get_patient_data_test(pid_index):\n",
    "    return x_test[pid_index*12:pid_index*12 + 12, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for subtask C\n",
    "# ---------------------- TRAINING DATA PREPROCESSING ---------------------------- \n",
    "# Imputation\n",
    "x_imputed = np.zeros_like(x_)\n",
    "for pid_idx in range(len(IdF_unique)):\n",
    "    # get training data for a patient (dim 12 x d)\n",
    "    x_patient = get_patient_data(pid_idx)\n",
    "    x_patient_imputed = np.zeros_like(x_patient) # initialise imputed array for each patient\n",
    "    \n",
    "    # deal with column seperately\n",
    "    for col in range(len(x_patient[1, :])):\n",
    "        # Count number of Nan in each column\n",
    "        nan_count = np.isnan(x_patient[:, col]).sum()\n",
    "        \n",
    "        if nan_count>0:\n",
    "            # Imputation Strategy\n",
    "            strategy = impute_strategy(nan_count)\n",
    "            # Impute data for each column\n",
    "            x_patient_col = x_patient[:, col].reshape(-1, 1) #reshape to be size (12,1)\n",
    "            impute_estimator = impute_data(strategy, pop_median[col])\n",
    "            x_patient_imputed[:, col] = impute_estimator.fit_transform(x_patient_col).reshape(-1) # reshape to be size (12,)\n",
    "        else:\n",
    "            x_patient_imputed[:, col] = x_patient[:, col]           \n",
    "    # Concatenate imputed data for every patient\n",
    "    x_imputed[pid_idx*12:pid_idx*12 + 12, :] = x_patient_imputed\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "# ---------------------- TEST DATA PREPROCESSING ---------------------------- \n",
    "# Imputation\n",
    "x_test_imputed = np.zeros_like(x_test)\n",
    "for pid_idx in range(len(IdF_test_unique)):\n",
    "    # get training data for a patient (dim 12 x d)\n",
    "    x_test_patient = get_patient_data_test(pid_idx)\n",
    "    x_test_patient_imputed = np.zeros_like(x_test_patient) # initialise imputed array for each patient\n",
    "    \n",
    "    # deal with column seperately\n",
    "    for col in range(len(x_test_patient[1, :])):\n",
    "        # Count number of Nan in each column\n",
    "        nan_count = np.isnan(x_test_patient[:, col]).sum()\n",
    "        \n",
    "        if nan_count>0:\n",
    "            # Imputation Strategy\n",
    "            strategy = impute_strategy(nan_count)\n",
    "            # Impute data for each column\n",
    "            x_test_patient_col = x_test_patient[:, col].reshape(-1, 1) #reshape to be size (12,1)\n",
    "            impute_estimator = impute_data(strategy, pop_median_test[col])\n",
    "            x_test_patient_imputed[:, col] = impute_estimator.fit_transform(x_test_patient_col).reshape(-1) # reshape to be size (12,)\n",
    "        else:\n",
    "            x_test_patient_imputed[:, col] = x_test_patient[:, col]           \n",
    "    # Concatenate imputed data for every patient\n",
    "    x_test_imputed[pid_idx*12:pid_idx*12 + 12, :] = x_test_patient_imputed\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "# Once the data has been processed, save it to avoid recomputing it\n",
    "np.save('x_imputed.npy', x_imputed)\n",
    "np.save('x_test_imputed.npy', x_test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for subtask A, B\n",
    "# ---------------------- TRAINING DATA PREPROCESSING ---------------------------- \n",
    "# Imputation\n",
    "x_imputed = np.zeros((int(x_.shape[0]/12), 35))\n",
    "\n",
    "for pid_idx in range(len(IdF_unique)):\n",
    "    # get training data for a patient (dim 12 x d)\n",
    "    x_patient = get_patient_data(pid_idx)\n",
    "    x_patient_imputed = np.array([0.]*35)\n",
    "    \n",
    "    # deal with column seperately\n",
    "    for col in range(len(x_patient[1, :])):\n",
    "        # Count number of Nan in each column\n",
    "        nan_count = np.isnan(x_patient[:, col]).sum()\n",
    "        \n",
    "        if nan_count<12:\n",
    "            x_patient_imputed[col]=np.nanmean(x_patient, axis = 0)[col]\n",
    "        else:\n",
    "            x_patient_imputed[col] = -1           \n",
    "    # Concatenate imputed data for every patient\n",
    "    x_imputed[pid_idx, :] = x_patient_imputed\n",
    "    \n",
    "print(x_imputed)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "# ---------------------- TEST DATA PREPROCESSING ---------------------------- \n",
    "# Imputation\n",
    "x_test_imputed = np.zeros((int(x_test.shape[0]/12), 35))\n",
    "\n",
    "for pid_idx in range(len(IdF_test_unique)):\n",
    "    # get training data for a patient (dim 12 x d)\n",
    "    x_test_patient = get_patient_data_test(pid_idx)\n",
    "    x_test_patient_imputed = np.array([0.]*35)\n",
    "    \n",
    "    # deal with column seperately\n",
    "    for col in range(len(x_test_patient[1, :])):\n",
    "        # Count number of Nan in each column\n",
    "        nan_count = np.isnan(x_test_patient[:, col]).sum()\n",
    "        \n",
    "        if nan_count<12:\n",
    "            x_test_patient_imputed[col]=np.nanmean(x_test_patient, axis = 0)[col]\n",
    "        else:\n",
    "            x_test_patient_imputed[col] = -1           \n",
    "    # Concatenate imputed data for every patient\n",
    "    x_test_imputed[pid_idx, :] = x_test_patient_imputed\n",
    "    \n",
    "print(x_test_imputed)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "# Once the data has been processed, save it to avoid recomputing it\n",
    "np.save('x_imputed2.npy', x_imputed)\n",
    "np.save('x_test_imputed2.npy', x_test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels=['pid','LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total',\n",
    "         'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "         'LABEL_Bilirubin_direct', 'LABEL_EtCO2','LABEL_Sepsis','LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "output = pd.DataFrame(np.array([[0]*16]), columns=Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imputed data, in case it has already been calculated and saves\n",
    "x_imputed = np.load('x_imputed2.npy',allow_pickle='TRUE')\n",
    "x_test_imputed = np.load('x_test_imputed2.npy',allow_pickle='TRUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cross-validation, skipped\n",
    "# ---------------------- SUBTASK A,B: CLASSIFICATION ----------------------------\n",
    "# c=RandomForestClassifier(min_samples_leaf=20, class_weight='balanced', n_estimators=100)\n",
    "# brm_clf = OneVsRestClassifier(c)\n",
    "\n",
    "# # each row contains the total data for one patient\n",
    "# # x_imputed = x_imputed.reshape(-1, 36)\n",
    "# cnt = 0\n",
    "\n",
    "# # 10 fold cross-validation to choose hyperparameters\n",
    "# num_fold = 10\n",
    "# kf = KFold(n_splits=num_fold)\n",
    "# score = 0\n",
    "# for train_index, val_index in kf.split(x_imputed): # split the data into validation and training sets\n",
    "#     print(cnt, 'starting .. ', end=\"\")\n",
    "\n",
    "#     x_train = x_imputed[train_index]\n",
    "#     #x_train_scaled = scaler.fit_transform(x_train)\n",
    "#     x_val = x_imputed[val_index]\n",
    "#     #x_val_scaled = scaler.transform(x_val)\n",
    "\n",
    "#     y_train = y_[train_index, 0:11]\n",
    "#     y_val = y_[val_index, 0:11]\n",
    "\n",
    "#     brm_clf.fit(x_train, y_train) # apply model to training data\n",
    "#     y_est = brm_clf.predict_proba(x_val) # predict labels using validation data\n",
    "\n",
    "#     score += np.mean([(roc_auc_score(y_val[:, k], y_est[:, k])) for k in range(11)])\n",
    "#     print(\"Task A score :\", np.mean([(roc_auc_score(y_val[:, k], y_est[:, k])) for k in range(10)]), \"Task B score :\", roc_auc_score(y_val[:, 10], y_est[:, 10]))\n",
    "#     print(\"done\")\n",
    "#     cnt += 1\n",
    "    \n",
    "# # EVALUATION of model\n",
    "# # Calculate average auroc score for all 10 folds\n",
    "# avg_score = score/num_fold\n",
    "\n",
    "# print(avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Random Forest on the whole training set\n",
    "x_tot = x_imputed\n",
    "y_tot = y_[:, 0:11]\n",
    "\n",
    "c=RandomForestClassifier(min_samples_leaf=20, class_weight='balanced', n_estimators=100)\n",
    "# c.fit(x_tot,y_tot)\n",
    "\n",
    "brm_clf = OneVsRestClassifier(c)\n",
    "brm_clf.fit(x_tot, y_tot)\n",
    "\n",
    "# Predict the Labels for the test features\n",
    "x_test_tasksA_B = x_test_imputed\n",
    "y_est_test=brm_clf.predict_proba(x_test_tasksA_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write in the output dataframe the obtained values\n",
    "TESTS = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total',\n",
    "         'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "         'LABEL_Bilirubin_direct', 'LABEL_EtCO2','LABEL_Sepsis']\n",
    "i=0\n",
    "for pid in IdF_test_unique:\n",
    "    output.loc[i,'pid']=pid\n",
    "    output.loc[i,TESTS]=y_est_test[i,:]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imputed data, in case it has already been calculated and saves\n",
    "x_imputed = np.load('x_imputed.npy',allow_pickle='TRUE')\n",
    "x_test_imputed = np.load('x_test_imputed.npy',allow_pickle='TRUE')\n",
    "\n",
    "x_imputed = x_imputed.reshape(-1, 12*36)\n",
    "x_test_imputed = x_test_imputed.reshape(-1, 12*36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- SUBTASK C: REGRESSION ----------------------------\n",
    "def taskC_regressor(alpha_):\n",
    "    c=Ridge(alpha=alpha_)\n",
    "\n",
    "    # 10 fold cross-validation to choose hyperparameters\n",
    "    num_fold = 10\n",
    "    kf = KFold(n_splits=num_fold)\n",
    "    score = 0\n",
    "    for train_index, val_index in kf.split(x_imputed): # split the data into validation and training sets\n",
    "        x_train = x_imputed[train_index]\n",
    "        x_train_scaled = scaler.fit_transform(x_train)\n",
    "        x_val = x_imputed[val_index]\n",
    "        x_val_scaled = scaler.transform(x_val)\n",
    "        \n",
    "        y_train = y_[train_index, 11:15]\n",
    "        y_val = y_[val_index, 11:15]\n",
    " \n",
    "        c.fit(x_train_scaled, y_train) # apply model to training data\n",
    "        y_est = np.transpose(c.predict(x_val_scaled)) # predict labels using validation data\n",
    "        \n",
    "        score += np.mean([0.5 + 0.5*np.maximum(0, r2_score(y_val[:,k],y_est[k,:])) for k in range(4)])\n",
    "        print(np.mean([0.5 + 0.5*np.maximum(0, r2_score(y_val[:,k],y_est[k,:])) for k in range(4)]))\n",
    "\n",
    "    # EVALUATION of model\n",
    "    # Calculate average auroc score for all 10 folds\n",
    "    avg_score = score/num_fold\n",
    "\n",
    "    return avg_score\n",
    "\n",
    "alpha_values = np.logspace(-3, 3, num=50, base=10.) #50 values between 10-3 to 10+3 \n",
    "print (alpha_values)\n",
    "avg_scores = [taskC_regressor(alpha) for alpha in alpha_values]\n",
    "print(avg_scores)\n",
    "\n",
    "# find alpha that has the highest score\n",
    "best_alpha = alpha_values[np.argmax(avg_scores)]\n",
    "print(best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best Ridge regression on the whole training set\n",
    "x_tot_scaled = scaler.fit_transform(x_imputed)\n",
    "y_tot = y_[:, 11:15]\n",
    "\n",
    "c=Ridge(alpha=best_alpha)\n",
    "c.fit(x_tot_scaled, y_tot)\n",
    "\n",
    "x_test_scaled=scaler.transform(x_test_imputed)\n",
    "y_est_test=(c.predict(x_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write in the output dataframe the obtained values\n",
    "i=0\n",
    "for pid in IdF_test_unique:\n",
    "    output.loc[i,'pid']=int(pid)\n",
    "    output.loc[i,['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']]=y_est_test[i, :]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output (predicted labels for the test features)\n",
    "# output.to_csv('prediction2.csv', index=False, float_format='%.3f')\n",
    "compression_opts = dict(method='zip', archive_name='prediction.csv')\n",
    "output.to_csv('prediction.zip', index=False, float_format='%.3f', compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
